<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Android | 大狗]]></title>
  <link href="http://chainsaw.github.io/blog/categories/android/atom.xml" rel="self"/>
  <link href="http://chainsaw.github.io/"/>
  <updated>2013-08-29T00:08:05+08:00</updated>
  <id>http://chainsaw.github.io/</id>
  <author>
    <name><![CDATA[chainsaw]]></name>
    <email><![CDATA[ywp123@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Android官方编程建议]]></title>
    <link href="http://chainsaw.github.io/blog/2013/08/27/android-performance-tips/"/>
    <updated>2013-08-27T21:28:00+08:00</updated>
    <id>http://chainsaw.github.io/blog/2013/08/27/android-performance-tips</id>
    <content type="html"><![CDATA[<p>（原文<a href="http://developer.android.com/training/articles/perf-tips.html">http://developer.android.com/training/articles/perf-tips.html</a>）</p>

<p>这篇文档主要介绍一些微优化，将这些优化技巧组合起来将使你的应用性能整体得到提升，当然这不会造成非常戏剧化的性能提升。本文中所提到的技巧可以作为小技巧帮助你养成良好和高效的编码习惯。</p>

<p>编写高效的代码有两条基本原则：</p>

<ul>
<li>不要做你不需要做的工作</li>
<li>如果可以避免，就不要申请内存</li>
</ul>


<p>当我们进行微优化的时候面对的最棘手的问题是你的应用需要运行在各种不同类型的硬件上，不同版本的VM运行在不同的处理器上的时候会有不同的运行速度，因此不能武断的说“设备X比设备Y运行速度快F”。模拟器只能告诉你非常有限的性能信息，同时支持JIT的设备上最适合运行的代码和不支持JIT的设备所适合运行的代码是不一样的。</p>

<p>为了保证你的应用能在很多设备上表现良好，你必须保证你的代码在每个层面上都是最优的.</p>

<h3>避免生成不需要的对象</h3>

<p>生成对象永远不是免费的。当你在你的应用中申请了太多的对象的时候，你就会强制系统执行定期的垃圾收集，这会对用户体验造成不好的影响（卡顿）。Android 2.3开始提出的并发垃圾收集器可以帮忙减轻这样的问题，但是这些不需要的工作还是应该要避免。下面是一些例子：</p>

<ul>
<li>如果你有一个方法返回一个String，然后你知道这个String会被连接到其他StringBuffer上，那就直接将这个方法连接过去，而不是创建一个临时的变量用来转接。</li>
<li>当你需要从一串输入值中返回一个字符串的时候，直接返回原始数据的subString而不是建立一个新的对象。这样做虽然会创建一个新的String对象，但是它会共享原有数据的char[]数据。（结果就是如果你只使用原始输入数据的一小部分内容，这部分内容会始终留在内存中）</li>
<li>int数组比Integer数组要好很多，两个并行的int数组比(int,int)对象组成的数组好，其他的原始类型组合也有相同的特性。</li>
<li>如果你需要实现一个存放(Foo,Bar)对象的容器，记住Foo[]和Bar[]比自定义一个(Foo,Bar)对象性能好。</li>
</ul>


<p>总体来说，尽可能避免创建临时对象。创建的对象越少，垃圾回收的频率会越低，这会直接影响用户体验。</p>

<h3>尽可能的使用静态方法</h3>

<p>如果你不需要访问一个对象的变量，那就把对象里面的方法设计为静态的，调用静态方法会提升15%-20%的速度。这同样是一个很好的实践，因为把方法设计成静态就等于明确告诉调用者对方法的调用不会改变对象的状态。</p>

<h3>使用Static Final来定义常量</h3>

<p>简单分析下下面的两个定义</p>

<p><code>
static int intVal = 42;
static String strVal = "hello,world";
</code></p>

<p>编译器会生成一个类的初始化方法，名为<clinit>，当这个类第一次被使用的时候会执行这个方法。这个方法会把42存到intVal里面，然后会从类文件的String常量表里面为strVal提取出一个引用。当之后这些值被引用的时候，他们通过值查找来找到。</p>

<p>我们可以使用final关键字来优化这一过程</p>

<p><code>
static final int intVal = 42;
static final String strVal = "hello,world";
</code></p>

<p>这样做之后，类文件将不再需要<clinit>方法，这些常量将由DEX文件中的静态变量初始化负责。代码调用intVal的时候会直接使用42，调用strVal的时候会使用一个消耗比较小的“String常量”指令替代非final时使用的值查找。</p>

<h3>避免使用内部的Getters/Setters</h3>

<p>在一般的面向对象语言中，Getter和Setter是很好的编程习惯，它可以帮助你做一些访问控制或者在访问时做一些其他的操作。</p>

<p>但是在Android中，这并不是一个很好的习惯，调用虚拟方法的成本永远比直接访问变量来的高。当你在编写公用的接口的时候，按照规范编写getter和setter是合理的，但是在你的类内部，你应该每次都直接访问变量。</p>

<p>在没有JIT的时候，直接访问变量比访问getter快三倍，当有JIT的时候，直接访问变量的速度会快七倍。</p>

<h3>使用强化的for循环语句</h3>

<p>```
static class Foo {</p>

<pre><code>int mSplat;
</code></pre>

<p>}</p>

<p>Foo[] mArray = &hellip;</p>

<p>public void zero() {</p>

<pre><code>int sum = 0;
for (int i = 0; i &lt; mArray.length; ++i) {
    sum += mArray[i].mSplat;
}
</code></pre>

<p>}</p>

<p>public void one() {</p>

<pre><code>int sum = 0;
Foo[] localArray = mArray;
int len = localArray.length;

for (int i = 0; i &lt; len; ++i) {
    sum += localArray[i].mSplat;
}
</code></pre>

<p>}</p>

<p>public void two() {</p>

<pre><code>int sum = 0;
for (Foo a : mArray) {
    sum += a.mSplat;
}
</code></pre>

<p>}
```</p>

<p>上面三个方法中，方法zero()是最慢的，因为每次循环都回去计算一次length，这一步无法被JIT或者其他编译器优化。</p>

<p>方法one()稍微快一些，将length存放在本地变量中，不需要每次都进行运算。</p>

<p>方法two()在没有使用JIT的设备上速度最快，但是在使用JIT的设备上和one()差不多，它使用了JAVA 1.5版本开始有的强化的for循环。</p>

<p>因此总体来说你应该使用强化的for循环。但是当你需要遍历一个ArrayList的时候，你应该选择用普通的for循环，这会为你带来三倍的速度提升。（原文没说原因，接下来研究一下）</p>

<h3>使用包替代对私有类的私有访问</h3>

<p>```
public class Foo {</p>

<pre><code>private class Inner {
    void stuff() {
        Foo.this.doStuff(Foo.this.mValue);
    }
}

private int mValue;

public void run() {
    Inner in = new Inner();
    mValue = 27;
    in.stuff();
}

private void doStuff(int value) {
    System.out.println("Value is " + value);
}
</code></pre>

<p>}
```</p>

<p>在上面的例子里，我们定义了一个私有的内部类(Foo$Inner)，这个类直接访问外部类的私有方法和私有变量。这样做是合法的，代码能正常打印出"Value is 27"。</p>

<p>这里存在的的问题是：尽管JAVA语言允许内部类访问外部类的私有方法，但是虚拟机认为从Foo$Inner里面直接访问Foo的私有方法是非法的，因为Foo和Foo$Inner是不同的类。为了实现这样的功能，编译器会生成一组合成方法：</p>

<p>```
/<em>package</em>/ static int Foo.access$100(Foo foo) {</p>

<pre><code>return foo.mValue;
</code></pre>

<p>}
/<em>package</em>/ static void Foo.access$200(Foo foo, int value) {</p>

<pre><code>foo.doStuff(value);
</code></pre>

<p>}
```</p>

<p>每当你需要调用私有类中的方法的时候，系统会自动调用生成的getter方法来实现调用。前面已经提过，通过setter和getter方法来访问变量是非常低效的，因此这样做在无形中增加了系统的消耗，降低了性能。</p>

<p>如果你必须在对性能要求很高的点使用类似的代码，建议将需要访问的变量定义为包级别的访问权限，这样同时会造成同一个包里面的代码都可以访问这些变量，因此不应该在公开的api中使用这样的访问权限。</p>

<h3>避免使用浮点数</h3>

<p>这里有一条经验法则：在Android设备上，浮点数比整数的运算效率低两倍。</p>

<p>在速度层面上，float和double效果差不多，double会比float大一倍。</p>

<p>就算是使用整数，乘法比除法和余除效率高很多，除法和余除是通过软件来实现而不是硬件加速实现的。</p>

<h3>了解和使用系统库</h3>

<p>在Android中，很多系统库都做了专门的调优，因此使用系统方法基本上都会比自己实现方法来的高效。很多JAVA的方法都已经由Dalvik做过专门的优化了，比如String.indexOf()和类似的API，类似的System.arraycopy()方法比手写的循环快9倍。</p>

<h3>谨慎使用本地方法</h3>

<p>通过Android NDK编写本地代码开发应用并不会比使用JAVA编程来的高效。一个主要的原因是JAVA做本地代码转换的时候需要消耗一部分性能，JIT无法优化这一部分功能。当你使用本地代码来实现某些功能的时候，你可能需要编译很多个不同的拷贝来适配不同的设备。</p>

<p>本地代码最主要的用途是将你已有的代码编译到Android中来节省开发时间，本地代码并不能加速你应用中那些本来用JAVA实现的代码。</p>

<h3>性能的秘密</h3>

<p>当设备上不支持JIT的时候，直接通过变量调用方法比通过接口调用方法要更高效。（打个比方调用HashMap map比调用Map map更高效，尽管两种情况下map都是一个HashMap）速度的差别在6%左右，如果设备上有JIT，这个差别将忽略不计。</p>

<p>在没有JIT的设备上，缓存一个变量用来访问比每次都直接访问一个变量要快20%。</p>

<h3>总是进行测量</h3>

<p>在你开始优化之前，你需要确信你知道你需要解决的问题是什么。确保你能准确的测量你现有的性能，否则你将无法知道你的努力给你带来了多大的成效。</p>

<p>本文中所有的申明都有相关的标准，这些标准可以在<a href="https://code.google.com/p/dalvik/source/browse/#svn/trunk/benchmarks">https://code.google.com/p/dalvik/source/browse/#svn/trunk/benchmarks</a>找到。</p>

<p>这些数据是通过<a href="https://code.google.com/p/caliper/">Caliper</a>框架来实现的。强烈推荐使用Caliper来实现你自己的检测数据。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dalvik虚拟机结构]]></title>
    <link href="http://chainsaw.github.io/blog/2013/08/26/dalvik-virtual-machine/"/>
    <updated>2013-08-26T15:03:00+08:00</updated>
    <id>http://chainsaw.github.io/blog/2013/08/26/dalvik-virtual-machine</id>
    <content type="html"><![CDATA[<h2>背景</h2>

<p>Java这个语言最大的特性之一就是“一次编写，处处运行”。这项能力主要来自于Java平台（JAVA Platform）,而Java平台的基础就是Java虚拟机（JVM）。</p>

<p>在桌面端(JSE)和服务器端(JEE)，Java平台已经基本实现了这个特性，但是移动端(JME)的Java平台非常碎片化，需要非常多的配置和包来适配不同的设备，这让普通的开发者很是头痛，因此当Google决定用Java作为android的开发语言的时候，它放弃了JME和JVM，使用Dalvik虚拟机。于此同时，Google也对Java语言的标准库进行了限制和扩展，形成了一套独特的非标准Java平台。</p>

<h2>局限性</h2>

<p>Android平台是为那些只拥有有限的CPU、RAM、ROM的设备设计的，Android设备的最低硬件要求如下：</p>

<table>
<thead>
<tr>
<th></th>
<th> 设备 </th>
<th> 最低要求 </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td> 芯片 </td>
<td> 基于ARM  </td>
</tr>
<tr>
<td></td>
<td> 内存 </td>
<td> 128MB RAM;256MB 闪存  </td>
</tr>
<tr>
<td></td>
<td>外部存储</td>
<td>Mini SD 或者Micro SD</td>
</tr>
<tr>
<td></td>
<td>主显示设备</td>
<td>QVGA TFT LCD或者更大；16位或者更多的色彩</td>
</tr>
<tr>
<td></td>
<td>摄像头</td>
<td>200万像素CMOS</td>
</tr>
<tr>
<td></td>
<td>USB</td>
<td>标准mini-B USB接口</td>
</tr>
<tr>
<td></td>
<td>蓝牙</td>
<td>1.2或2.0标准</td>
</tr>
</tbody>
</table>


<p>现在的市场上几乎所有的智能手机都可以很轻松的满足以上这一些条件，但是这些条件也从侧面反映出Android平台可以被使用于很多资源非常有限的设备上。</p>

<p>当一个应用平台需要支持非常多的设备和环境的时候，将这个平台从底层操作系统和硬件设备中抽象出来就显得格外重要了。</p>

<p>当应用开发的生态系统形成之后，成千上万的第三方开发者会开发出各式各样的应用。在这样的大前提下，要做到系统和应用本身的稳定和安全，应用必须有严格的策略制约，同时应用不能访问任何系统内部或者其他应用内的接口。</p>

<p>以上这些要求总结一下，就是Android runtime必须支持一下几点：</p>

<ul>
<li>有限的处理器速度</li>
<li>有限的RAM</li>
<li>没有交换区</li>
<li>使用电池作为电源</li>
<li>不同的硬件设备</li>
<li>应用运行时的沙盒(runtime sandbox)</li>
</ul>


<h2>设计概述</h2>

<p>由于Android应用runtime必须支持不同的硬件设备，而且考虑到安全、性能和稳定性的因素，Android应用必须在沙盒中运行，这时虚拟机就变成了一个显而易见的选择。但是使用虚拟机并不能平衡你对于低内存，低处理器速度要求。</p>

<p>Google又是如何来满足这些某种意义上自我冲突的要求的呐？</p>

<p>Google的解决方案是这样的：</p>

<blockquote><p>每一个Android应用程序都运行在一个独立的进程，拥有独立的Dalvik虚拟机实例。Dalvik设计的原则就是同一个设备可以非常高效的同时运行多个虚拟机。Dalvik的可执行文件是为最小化内存占用而优化的。Dalvik虚拟机是基于寄存器开发的，可以运行由Java编译产生的.class文件通过dx工具再次转化生成的.dex格式文件。
Dalvik虚拟机依赖Linux内核来执行某些功能，比如线程处理和底层内存管理。</p></blockquote>

<p>让每一个应用程序运行在独立的进程和独立的虚拟机中这样的机制，不仅要求多个虚拟机同时运行的时候需要高效，同时也要求创建虚拟机的过程是非常高效的。</p>

<p>本文接下来的部分分析Dalvik虚拟机在受到上一章所说的种种制约之下的设计抉择，主要分为.dex文件格式，Zygote，基于寄存器的构架和安全机制这几个部分。</p>

<h3>DEX文件格式</h3>

<p>在标准的Java环境中，Java源代码被编译成Java字节码，存放在.class文件中。.class文件有JVM在运行态的时候读取，Java代码中的每一个类都会生成一个.class文件。</p>

<p>在Android平台上，Java源代码仍然会被编译成.class文件，但是当.class文件生成之后，系统会使用dx工具把.class文件转换成.dex文件。一个.class文件只包含一个类，而一个.dex文件可以包含很多类，只有.dex文件才能在Dalvik虚拟机上运行。</p>

<p>.dex文件主要是为了减少内存占用和分享数据而设计的。
.dex文件和.jar文件的转换如下图所示：</p>

<p><img src="/images/class_to_dex.jpg" title="dex文件结构" alt="alt text" /></p>

<p>.dex文件主要通过使用共享的，指定类型的常量池来节约内存。常量池中存放这些类中使用的所有常量，这些常量通过常量池中的索引进行引用。通过这样的方式，可以将原来.class文件中重复使用的常量进行去重（.class文件的存放方式会造成一个常量存在多份拷贝，存在在不同的.class文件中）。</p>

<p>从图中可以看到，所有常量不是存放在同一个常量池中，而是通过类型来指定存放的。这样的存放方式可以使得常量更加颗粒化，从而进行更加深度的去重操作。
打个比方，现在存在两个方法签名分别是(Ljava/lang/String;Ljava/lang/Object;)Ljava/lang/String;和(Ljava/lang/String;Lcom/example/Foo;)Ljava/lang/String;。在.class文件中，这样的方法是分别混乱的存放着的，但是当转换成.dex文件的时候，Ljava/lang/String就会只存放一次，任何需要使用到它的地方去引用它。</p>

<p>共享常量池的做法使得常量的重复度降到了最低，但是同样带来了这样 一个问题，.dex文件中的指针和引用比.class中很明显的增多了。</p>

<p>共享常量池的主要目的是节省内存，但是实际上这样做能节省多少内存呐？跟具早期的一些研究，.class文件本身已经比较小了，但是由于将文件从外存中读入仍然是决定应用启动速度的重要因素，文件的大小还是很重要的。而每一个.class文件中常量部分占61%的文件大小，因此对常量池的优化能很显著的节省内存。
下面是Android开发团队所统计的数据：</p>

<table>
<thead>
<tr>
<th></th>
<th> 代码 </th>
<th> 未压缩Jar（bytes） </th>
<th>压缩的Jar（bytes）</th>
<th>未压缩的dex（bytes）</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td> 通用系统库      </td>
<td> 21,445,320(100%) </td>
<td> 10,662,048(50%) </td>
<td> 10,311,972(48%)</td>
</tr>
<tr>
<td></td>
<td> 浏览器应用</td>
<td>470,312(100%)</td>
<td>232,065(49%)</td>
<td>209,248(44%)</td>
</tr>
<tr>
<td></td>
<td> 闹钟应用</td>
<td>119,200(100%)</td>
<td>61,658(52%)</td>
<td>53,020(44%)</td>
</tr>
</tbody>
</table>


<p>对应这样的机制，Dalvik的垃圾回收机制也和普通的JVM垃圾回收不一样。由于每一个应用都是运行在独立的进程和VM中的，拥有独立的堆，所以垃圾回收的时候Dalvik会把共享对象标识为"reachable"，这样这些对象就不会被垃圾回收。当对象需要被写入时，对象会被拷贝到相应的堆中，然后该对象的标示符（GC在之前所设置的）也会被移动到堆中，在下次GC的时候，所有共享它的对象都会变成非共享。共享常量的原则是，共享的内存是只读的。</p>

<h3>Zygote</h3>

<p>由于每一个应用都拥有自己的VM实例，所以当应用启动的时候，VM实例需要很快的启动，同时占用最小的内存。Android使用一套名为Zygote的机制来实现在多个VM中共享代码，并且保证VM的快速启动。Zygote设计的时候假设系统中有非常大一部分核心类库和相关的堆可以被很多应用所共同使用，它同时假设这些堆结构都是只读的，也就是说基本上所有应用都只是使用这些数据而不是更改数据。这些特性被用来优化跨进程共享数据。</p>

<p>Zygote是一个在系统启动时开启的VM进程。当Zygote启动的时候，它会初始化一个Dalvik虚拟机，在这个虚拟机里面会预载入和初始化核心的类库。这些类库都是只读的，而且非常适合跨进程共享。</p>

<p>当Zygote启动之后，它会开始等待接受系统发来的socket请求，当请求到来的时候，Zygote就会fork出一个子进程来执行该应用程序，这样的方式比冷启动一个全新的VM要快很多。对于一些只读的系统库，所有虚拟机实例都和Zygote共享一块内存区域，大大节省了内存开销。</p>

<p>Zygote中的共享区域的类库都是只读的，当应用要写入这些类库的时候，这部分要被写入的类库会被拷贝到fork出来的子进程中。这种copy-on-write的技术可以从最大程度上共享内存，同时还能保证应用之间的访问安全。</p>

<p>在传统的Java VM中，每一个VM都拥有一套完整的核心类库文件以及相关的堆对象，在VM之间时不共享内存的。</p>

<h3>基于寄存器的结构</h3>

<p>传统的虚拟机结构为了保证VM部署的简单，和编译器后端代码编写的简易性，使用了基于栈的结构。但是这样的结构会导致损失一部分性能。研究表明：</p>

<blockquote><p>基于寄存器的结构比基于栈的结构执行的VM指令少47%，但是基于寄存器的代码量会比基于栈的代码多25%，而这一部分代码增多只会增加1.07%的机器负载。总的来说基于寄存器的结构比基于栈的结构执行时间少32.3%</p></blockquote>

<p>由于Dalvik VM是在计算能力有限的设备上运行的，因此选择基于寄存器的结构也就变得非常合理了。
虚拟机中指令的解释执行时间主要花在以下三个方面：</p>

<ul>
<li>分发指令</li>
<li>访问运算数</li>
<li>执行运算</li>
</ul>


<p>其中“分发指令”这个环节对性能的影响最大。在基于寄存器的虚拟机里，可以更为有效的减少冗余指令的分发和减少内存的读写访问。比如：</p>

<p>```
执行a=b+c
基于栈：ILOAD c,ILOAD b,IADD,ISTORE a
基于寄存器: IADD a,b,c</p>

<p>```</p>

<p>虽然这样做带来了25%的代码量增加，但是通过转换成.dex的方式节省了部分代码量，从总体上来说还是比JVM的.class格式更节省内存使用的。</p>

<h3>安全</h3>

<p>Android的安全机制保证了：</p>

<blockquote><p>默认情况下，没有任何应用可以执行危害到其他应用程序、操作系统或者用户文件的操作。这些操作包括读写用户的私有文件、读写其他应用的文件、执行网络请求、保持设备唤醒状态等。</p></blockquote>

<p>Android的安全机制时通过系统级别和框架级别来维护的。由于每一个应该程序都运行在独立的进程上，操作系统会为每一个进程分配独立的用户ID，应用通过这个ID只能访问有限的系统资源和自己的数据文件。如果应用需要掌握更多的权限，可以在自身的Manifest文件中申明需要的权限，这些权限会在应用安装的时候由框架通过操作系统来赋予。</p>

<p>Dalvik VM进程之间虽然都共享同一份核心的库，但是为了安全，每一个VM进程都只有读的权限，无法编辑这些库。</p>
]]></content>
  </entry>
  
</feed>
